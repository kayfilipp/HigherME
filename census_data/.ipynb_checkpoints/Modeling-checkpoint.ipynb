{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "000250b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import degree_codes as dc\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-dark-palette')\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from imblearn.combine import SMOTETomek\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from dmba import classificationSummary, gainsChart\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59751226",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YEAR</th>\n",
       "      <th>MULTYEAR</th>\n",
       "      <th>SAMPLE</th>\n",
       "      <th>SERIAL</th>\n",
       "      <th>CBSERIAL</th>\n",
       "      <th>HHWT</th>\n",
       "      <th>CLUSTER</th>\n",
       "      <th>STATEFIP</th>\n",
       "      <th>STRATA</th>\n",
       "      <th>GQ</th>\n",
       "      <th>...</th>\n",
       "      <th>INCWAGE</th>\n",
       "      <th>State</th>\n",
       "      <th>under_represented</th>\n",
       "      <th>domestic_born</th>\n",
       "      <th>EDU_verbose</th>\n",
       "      <th>is_STEM_degree</th>\n",
       "      <th>Degree</th>\n",
       "      <th>Degree_D</th>\n",
       "      <th>JobRole</th>\n",
       "      <th>stemType</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020</td>\n",
       "      <td>2016</td>\n",
       "      <td>202003</td>\n",
       "      <td>6676264</td>\n",
       "      <td>2016000978820</td>\n",
       "      <td>5.15</td>\n",
       "      <td>2020066762643</td>\n",
       "      <td>55</td>\n",
       "      <td>10055</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>51776</td>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>High School</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>couriers and messengers</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020</td>\n",
       "      <td>2016</td>\n",
       "      <td>202003</td>\n",
       "      <td>4027595</td>\n",
       "      <td>2016000661290</td>\n",
       "      <td>17.51</td>\n",
       "      <td>2020040275953</td>\n",
       "      <td>36</td>\n",
       "      <td>60036</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>21573</td>\n",
       "      <td>New York</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>High School</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>miscellaneous production workers including equ...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020</td>\n",
       "      <td>2017</td>\n",
       "      <td>202003</td>\n",
       "      <td>5156019</td>\n",
       "      <td>2017000181278</td>\n",
       "      <td>6.18</td>\n",
       "      <td>2020051560193</td>\n",
       "      <td>42</td>\n",
       "      <td>370142</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Bachelor</td>\n",
       "      <td>0</td>\n",
       "      <td>Criminal Justice and Fire Protection</td>\n",
       "      <td>Criminal Justice and Fire Protection</td>\n",
       "      <td>elementary and middle school teachers</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   YEAR  MULTYEAR  SAMPLE   SERIAL       CBSERIAL   HHWT        CLUSTER  \\\n",
       "0  2020      2016  202003  6676264  2016000978820   5.15  2020066762643   \n",
       "1  2020      2016  202003  4027595  2016000661290  17.51  2020040275953   \n",
       "2  2020      2017  202003  5156019  2017000181278   6.18  2020051560193   \n",
       "\n",
       "   STATEFIP  STRATA  GQ  ...  INCWAGE         State  under_represented  \\\n",
       "0        55   10055   1  ...    51776     Wisconsin                  0   \n",
       "1        36   60036   1  ...    21573      New York                  0   \n",
       "2        42  370142   1  ...        0  Pennsylvania                  0   \n",
       "\n",
       "   domestic_born  EDU_verbose  is_STEM_degree  \\\n",
       "0              1  High School               0   \n",
       "1              1  High School               0   \n",
       "2              0     Bachelor               0   \n",
       "\n",
       "                                 Degree                              Degree_D  \\\n",
       "0                                   NaN                                   NaN   \n",
       "1                                   NaN                                   NaN   \n",
       "2  Criminal Justice and Fire Protection  Criminal Justice and Fire Protection   \n",
       "\n",
       "                                             JobRole  stemType  \n",
       "0                            couriers and messengers        -1  \n",
       "1  miscellaneous production workers including equ...        -1  \n",
       "2              elementary and middle school teachers        -1  \n",
       "\n",
       "[3 rows x 38 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('main_df.csv')\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19b248ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#selecting the feautures for modeling\n",
    "df_model=df[[\n",
    "    'SEX'\n",
    "    #,'RACE'\n",
    "    ,'AGE'\n",
    "    ,'domestic_born'\n",
    "    ,'EDU_verbose'\n",
    "    ,'is_STEM_degree'\n",
    "    ,'under_represented'\n",
    "    ,'stemType'\n",
    "]]\n",
    "del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef07b352",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1                                                                                 189173\n",
       "Research, Development, Design, and Practitioners                                     4052\n",
       "Managerial                                                                            768\n",
       "Research, Development, Design, and Practitioners; Technologists and Technicians       612\n",
       "Technologists and Technicians                                                         355\n",
       "Sales                                                                                  39\n",
       "Name: stemType, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_model['stemType'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff9ec7e7",
   "metadata": {},
   "source": [
    "In order to run any sort of modeling on stemType, our target variable, we have to binarize it by employing a lambda function. At this point, stemType indicates whether an individual works in STEM, rather than which STEM field they're employed in :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "902a7131",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "Name: stemType, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def binarize_stem(x):\n",
    "    if x == '-1':\n",
    "        return 0\n",
    "    return 1\n",
    "\n",
    "#binarize STEM\n",
    "df_model['stemType'] = df_model['stemType'].map(binarize_stem)\n",
    "\n",
    "#switch SEX from 1,2 to 0,1\n",
    "df_model['SEX'] = df_model['SEX']-1\n",
    "\n",
    "df_model['stemType'].head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2488c85",
   "metadata": {},
   "source": [
    "Given that there's several different levels of education, we would benefit from using dummy variables in our modeling for them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c43da3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#a = pd.get_dummies(df_model['RACE'], prefix = \"RACE\")# get dummy variables for Race\n",
    "b = pd.get_dummies(df_model['EDU_verbose'],prefix='EDU_verbose')#get dummy variables for Education\n",
    "\n",
    "frames = [\n",
    "    df_model\n",
    "    #, a\n",
    "    , b] # append them as a list\n",
    "df_model = pd.concat(frames, axis = 1)\n",
    "df_model=df_model.drop(columns = [\n",
    "    'EDU_verbose'\n",
    "    #, 'RACE'\n",
    "]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd9048d0",
   "metadata": {},
   "source": [
    "Finally, to keep scale consistent, we would want to normalize the AGE variable to avoid giving it more weight:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "63a6b975",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.448718\n",
       "1    0.487179\n",
       "2    0.217949\n",
       "Name: AGE, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "denom = df_model['AGE'].max() - df_model['AGE'].min()\n",
    "df_model['AGE'] = (df_model['AGE']-df_model['AGE'].min())/denom\n",
    "df_model['AGE'].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "386d1eee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    189173\n",
       "1      5826\n",
       "Name: stemType, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=df_model['stemType']\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249e2944",
   "metadata": {},
   "source": [
    "### Check for class imbalance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "09766e2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent of 0s: 97.01\n",
      "\n",
      "Percent of 1s: 2.99\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = pd.DataFrame(df_model['stemType'])\n",
    "percentage1 = round((data.stemType.sum() / data.shape[0]) * 100, 2) \n",
    "percentage0 = round(100 - percentage1, 2)\n",
    "print('Percent of 0s:', percentage0)\n",
    "print('\\nPercent of 1s:', percentage1)\n",
    "t=df_model['stemType'].value_counts().values\n",
    "sns.barplot([0,1],t)\n",
    "plt.title('Target variable count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d98f280",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_model.drop(columns=['stemType'])\n",
    "y = df_model['stemType']\n",
    "train_X, rem_X, train_y, rem_y = train_test_split(X, y, train_size=0.6, random_state=42, stratify = y)\n",
    "valid_X, test_X, valid_y, test_y = train_test_split(rem_X, rem_y, train_size=0.5, random_state=42, stratify = rem_y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b581ad37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set:\n",
      " 0    113503\n",
      "1      3496\n",
      "Name: stemType, dtype: int64 \n",
      " 0    0.970119\n",
      "1    0.029881\n",
      "Name: stemType, dtype: float64\n",
      "\n",
      "Validation Set:\n",
      " 0    37835\n",
      "1     1165\n",
      "Name: stemType, dtype: int64 \n",
      " 0    0.970128\n",
      "1    0.029872\n",
      "Name: stemType, dtype: float64\n",
      "\n",
      "Test Set:\n",
      " 0    37835\n",
      "1     1165\n",
      "Name: stemType, dtype: int64 \n",
      " 0    0.970128\n",
      "1    0.029872\n",
      "Name: stemType, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print('Training Set:\\n', train_y.value_counts(), '\\n', train_y.value_counts(normalize = True))\n",
    "print('\\nValidation Set:\\n', valid_y.value_counts(), '\\n', valid_y.value_counts(normalize = True))\n",
    "print('\\nTest Set:\\n', test_y.value_counts(), '\\n', test_y.value_counts(normalize = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2c89fc7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    train_X_res = pd.read_csv('SMOTE_df.csv')\n",
    "    train_y_res = pd.read_csv('SMOTE_df_target.csv')\n",
    "except:\n",
    "    # Fixing the class imbalance with tomekLinks and SMOTE\n",
    "    SMOTEtl = SMOTETomek(random_state = 42)\n",
    "\n",
    "    # fit predictor and target variable for training set only\n",
    "    train_X_res, train_y_res = SMOTEtl.fit_resample(train_X, train_y)\n",
    "\n",
    "    print('Original dataset shape:\\n', train_y.value_counts())\n",
    "    print('Resampled dataset shape:\\n', train_y_res.value_counts())\n",
    "\n",
    "    train_X_res.to_csv('SMOTE_df.csv',index=None)\n",
    "    train_y_res.to_csv('SMOTE_df_target.csv',index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b1dda4",
   "metadata": {},
   "source": [
    "We can also save our SMOTE data to .csv to avoid having to re-run this data during development work for future replications, which is handled in the **except** statement above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "552bb833",
   "metadata": {},
   "source": [
    "### Helper Function: Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fc2e2e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusionMatrices(model, title):\n",
    "    print(title + ' - training results')\n",
    "    classificationSummary(train_y_res, model.predict(train_X_res))\n",
    "    print(title + ' - validation results')\n",
    "    valid_pred = model.predict(valid_X)\n",
    "    classificationSummary(valid_y, valid_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d78fd4",
   "metadata": {},
   "source": [
    "### Helper Function: Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a3c9f6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evalMetrics(model,mod_predict,verbose=True):\n",
    "    # precision tp / (tp + fp)\n",
    "    precision = precision_score(test_y, mod_predict)\n",
    "    # recall: tp / (tp + fn)\n",
    "    recall = recall_score(test_y, mod_predict)\n",
    "    \n",
    "    # f1: 2 tp / (2 tp + fp + fn)\n",
    "    f1 = f1_score(test_y, mod_predict)\n",
    "    \n",
    "    # ROC AUC\n",
    "    lr_probs = model.predict_proba(test_X)\n",
    "    lr_probs = lr_probs[:, 1]\n",
    "    auc = roc_auc_score(test_y, lr_probs)\n",
    "    \n",
    "    if verbose:\n",
    "        print('Precision: %f' % precision)\n",
    "        print('Recall: %f' % recall)\n",
    "        print('F1 score: %f' % f1)\n",
    "        print('ROC AUC: %f' % auc)\n",
    "        \n",
    "    return {\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1,\n",
    "        \"roc_auc\":auc\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc5494d",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9989dbb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(train_X_res, train_y_res)\n",
    "confusionMatrices(gnb,'Naive Bayes')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b1751e",
   "metadata": {},
   "source": [
    "#### Evaluation and Confusion Matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93555f30",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gnb_pred = gnb.predict(test_X)\n",
    "evalMetrics(gnb,gnb_pred)\n",
    "classificationSummary(test_y, gnb_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a6cd44",
   "metadata": {},
   "source": [
    "### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8058a4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_reg = LogisticRegression(penalty=\"l1\", C=1e42, solver='liblinear', random_state = 1)\n",
    "logit_reg.fit(train_X_res, train_y_res)\n",
    "confusionMatrices(logit_reg, 'Logistic regression')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0baa5bce",
   "metadata": {},
   "source": [
    "#### Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb6f7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_pred = logit_reg.predict(test_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aace6b2",
   "metadata": {},
   "source": [
    "#### Evaluation and Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb435b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "evalMetrics(logit_reg,logit_pred)\n",
    "classificationSummary(test_y, logit_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6f4527a",
   "metadata": {},
   "source": [
    "### Random Forest - GridSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1613e2ba",
   "metadata": {},
   "source": [
    "To optimize random forest performance, we want to cycle through the number of estimators, the maximum tree depth, the log-loss, the cost function, and more:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d09671ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bootstrap': [True, False],\n",
      " 'max_depth': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, None],\n",
      " 'max_features': ['auto', 'sqrt'],\n",
      " 'min_samples_leaf': [1, 2, 4],\n",
      " 'min_samples_split': [2, 5, 10],\n",
      " 'n_estimators': [400, 450, 500, 550, 600]}\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(random_state = 1,verbose = 10)\n",
    "\n",
    "# Number of trees in random forest\n",
    "n_estimators = [400,450,500,550,600]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(1, 10, num = 10)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "pprint.pprint(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "699a0d79",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "'roc_auc_x' is not a valid scoring value. Use sklearn.metrics.get_scorer_names() to get valid options.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\users\\fkrasovsky\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\metrics\\_scorer.py:415\u001b[0m, in \u001b[0;36mget_scorer\u001b[1;34m(scoring)\u001b[0m\n\u001b[0;32m    414\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 415\u001b[0m     scorer \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(\u001b[43m_SCORERS\u001b[49m\u001b[43m[\u001b[49m\u001b[43mscoring\u001b[49m\u001b[43m]\u001b[49m)\n\u001b[0;32m    416\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n",
      "\u001b[1;31mKeyError\u001b[0m: 'roc_auc_x'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [33]\u001b[0m, in \u001b[0;36m<cell line: 13>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m rf_random \u001b[38;5;241m=\u001b[39m RandomizedSearchCV(\n\u001b[0;32m      3\u001b[0m     estimator \u001b[38;5;241m=\u001b[39m rf\n\u001b[0;32m      4\u001b[0m     , param_distributions \u001b[38;5;241m=\u001b[39m random_grid\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     10\u001b[0m     , scoring \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mroc_auc_x\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     11\u001b[0m )\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Fit the random search model\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m \u001b[43mrf_random\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_X_res\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_y_res\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\users\\fkrasovsky\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\model_selection\\_search.py:777\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    775\u001b[0m     scorers \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscoring\n\u001b[0;32m    776\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscoring \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscoring, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m--> 777\u001b[0m     scorers \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_scoring\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscoring\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    778\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    779\u001b[0m     scorers \u001b[38;5;241m=\u001b[39m _check_multimetric_scoring(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimator, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscoring)\n",
      "File \u001b[1;32mc:\\users\\fkrasovsky\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\metrics\\_scorer.py:464\u001b[0m, in \u001b[0;36mcheck_scoring\u001b[1;34m(estimator, scoring, allow_none)\u001b[0m\n\u001b[0;32m    459\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m    460\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mestimator should be an estimator implementing \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m method, \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m was passed\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    461\u001b[0m         \u001b[38;5;241m%\u001b[39m estimator\n\u001b[0;32m    462\u001b[0m     )\n\u001b[0;32m    463\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(scoring, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m--> 464\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_scorer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscoring\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    465\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m callable(scoring):\n\u001b[0;32m    466\u001b[0m     \u001b[38;5;66;03m# Heuristic to ensure user has not passed a metric\u001b[39;00m\n\u001b[0;32m    467\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(scoring, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__module__\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\users\\fkrasovsky\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\metrics\\_scorer.py:417\u001b[0m, in \u001b[0;36mget_scorer\u001b[1;34m(scoring)\u001b[0m\n\u001b[0;32m    415\u001b[0m         scorer \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(_SCORERS[scoring])\n\u001b[0;32m    416\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[1;32m--> 417\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    418\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m is not a valid scoring value. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    419\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUse sklearn.metrics.get_scorer_names() \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    420\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto get valid options.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m scoring\n\u001b[0;32m    421\u001b[0m         )\n\u001b[0;32m    422\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    423\u001b[0m     scorer \u001b[38;5;241m=\u001b[39m scoring\n",
      "\u001b[1;31mValueError\u001b[0m: 'roc_auc_x' is not a valid scoring value. Use sklearn.metrics.get_scorer_names() to get valid options."
     ]
    }
   ],
   "source": [
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random = RandomizedSearchCV(\n",
    "    estimator = rf\n",
    "    , param_distributions = random_grid\n",
    "    , n_iter = 100\n",
    "    , cv = 3\n",
    "    , verbose=10\n",
    "    , random_state=1\n",
    "    , n_jobs = -1\n",
    "    , scoring = 'roc_auc_x'\n",
    ")\n",
    "# Fit the random search model\n",
    "rf_random.fit(train_X_res, train_y_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb4bece6",
   "metadata": {},
   "source": [
    "We can see which parameters perform the best for our random forest:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec1ec3f",
   "metadata": {},
   "source": [
    "Continue by reviewing the array of ROC scores we got from our models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "476789b3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'scikit_learn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [37]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mscikit_learn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\n\u001b[0;32m      2\u001b[0m sklearn\u001b[38;5;241m.\u001b[39mmetrics\u001b[38;5;241m.\u001b[39mget_scorer_names()\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'scikit_learn'"
     ]
    }
   ],
   "source": [
    "import scikit_learn as sklearn\n",
    "sklearn.metrics.get_scorer_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4b99c157",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 1500 out of 1500 | elapsed:   10.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.107049\n",
      "Recall: 0.454936\n",
      "F1 score: 0.173316\n",
      "ROC AUC: 0.724531\n",
      "Confusion Matrix (Accuracy 0.8704)\n",
      "\n",
      "       Prediction\n",
      "Actual     0     1\n",
      "     0 33414  4421\n",
      "     1   635   530\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 1500 out of 1500 | elapsed:   10.6s finished\n"
     ]
    }
   ],
   "source": [
    "RandomForest_pred = rf_random.predict(test_X)\n",
    "evalMetrics(rf_random,RandomForest_pred)\n",
    "classificationSummary(test_y, RandomForest_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a19b829",
   "metadata": {},
   "source": [
    "We can also compare this with our original model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "02bc4602",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.107517\n",
      "Recall: 0.696137\n",
      "F1 score: 0.186266\n",
      "ROC AUC: 0.837011\n",
      "Confusion Matrix (Accuracy 0.8183)\n",
      "\n",
      "       Prediction\n",
      "Actual     0     1\n",
      "     0 31103  6732\n",
      "     1   354   811\n"
     ]
    }
   ],
   "source": [
    "RandomForest = RandomForestClassifier(\n",
    "    n_estimators=500\n",
    "    , random_state=1\n",
    "    , max_depth = 6\n",
    ")\n",
    "RandomForest.fit(train_X_res, train_y_res)\n",
    "RandomForest_pred = RandomForest.predict(test_X)\n",
    "evalMetrics(RandomForest,RandomForest_pred)\n",
    "classificationSummary(test_y, RandomForest_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fdf3bb1",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ad617a30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network - training results\n",
      "Confusion Matrix (Accuracy 0.7632)\n",
      "\n",
      "       Prediction\n",
      "Actual     0     1\n",
      "     0 93503 19916\n",
      "     1 33795 79624\n",
      "Neural Network - validation results\n",
      "Confusion Matrix (Accuracy 0.8175)\n",
      "\n",
      "       Prediction\n",
      "Actual     0     1\n",
      "     0 31112  6723\n",
      "     1   395   770\n"
     ]
    }
   ],
   "source": [
    "neuralNet = MLPClassifier(\n",
    "    hidden_layer_sizes=(5)\n",
    "    , activation='logistic'\n",
    "    , solver='lbfgs'\n",
    "    , max_iter=2000, \n",
    "    random_state=1\n",
    ")\n",
    "neuralNet.fit(train_X_res, train_y_res)\n",
    "confusionMatrices(neuralNet, 'Neural Network')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "374000cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix (Accuracy 0.8181)\n",
      "\n",
      "       Prediction\n",
      "Actual     0     1\n",
      "     0 31084  6751\n",
      "     1   345   820\n"
     ]
    }
   ],
   "source": [
    "neuralNet_pred = neuralNet.predict(test_X)\n",
    "classificationSummary(test_y, neuralNet_pred )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "52b962e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.108308\n",
      "Recall: 0.703863\n",
      "F1 score: 0.187729\n",
      "ROC AUC: 0.840197\n"
     ]
    }
   ],
   "source": [
    "# precision tp / (tp + fp)\n",
    "precision = precision_score(test_y, neuralNet_pred )\n",
    "print('Precision: %f' % precision)\n",
    "# recall: tp / (tp + fn)\n",
    "recall = recall_score(test_y, neuralNet_pred )\n",
    "print('Recall: %f' % recall)\n",
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "f1 = f1_score(test_y, neuralNet_pred )\n",
    "print('F1 score: %f' % f1)\n",
    "# ROC AUC\n",
    "nn_probs = neuralNet.predict_proba(test_X)\n",
    "nn_probs = nn_probs[:, 1]\n",
    "auc = roc_auc_score(test_y, nn_probs)\n",
    "print('ROC AUC: %f' % auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "d6ab3d50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Models</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1_Score</th>\n",
       "      <th>ROC AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.782205</td>\n",
       "      <td>0.093059</td>\n",
       "      <td>0.719313</td>\n",
       "      <td>0.164798</td>\n",
       "      <td>0.832059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.818308</td>\n",
       "      <td>0.107517</td>\n",
       "      <td>0.696137</td>\n",
       "      <td>0.186266</td>\n",
       "      <td>0.837011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Neural Network</td>\n",
       "      <td>0.818051</td>\n",
       "      <td>0.108308</td>\n",
       "      <td>0.703863</td>\n",
       "      <td>0.187729</td>\n",
       "      <td>0.840197</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Models  Accuracy  Precision    Recall  F1_Score   ROC AUC\n",
       "0  Logistic Regression  0.782205   0.093059  0.719313  0.164798  0.832059\n",
       "1        Random Forest  0.818308   0.107517  0.696137  0.186266  0.837011\n",
       "2       Neural Network  0.818051   0.108308  0.703863  0.187729  0.840197"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table = {'Models':[\"Logistic Regression\", \n",
    "                   \"Random Forest\",\n",
    "                   \"Neural Network\"],\n",
    "         'Accuracy':[accuracy_score(test_y, logit_pred),\n",
    "                     \n",
    "                     accuracy_score(test_y, RandomForest_pred),\n",
    "                     \n",
    "                     accuracy_score(test_y, neuralNet_pred)],\n",
    "         'Precision':[precision_score(test_y, logit_pred),\n",
    "                   \n",
    "                 \n",
    "                      precision_score(test_y, RandomForest_pred),\n",
    "                      \n",
    "                      precision_score(test_y, neuralNet_pred) ],\n",
    "         \"Recall\":[recall_score(test_y, logit_pred),\n",
    "               \n",
    "                   recall_score(test_y, RandomForest_pred),\n",
    "          \n",
    "                   recall_score(test_y,neuralNet_pred)],\n",
    "         \"F1_Score\":[f1_score(test_y, logit_pred),\n",
    "                    \n",
    "                     f1_score(test_y, RandomForest_pred),\n",
    "                   \n",
    "                     f1_score(test_y,neuralNet_pred)],\n",
    "         \"ROC AUC\":[roc_auc_score(test_y, lr_probs),\n",
    "                   \n",
    "                    roc_auc_score(test_y, rf_probs),\n",
    "                  \n",
    "                    roc_auc_score(test_y,  nn_probs)]\n",
    "}\n",
    "table_report = pd.DataFrame(table)\n",
    "# print the data\n",
    "table_report"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
